{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Cloning the files required"
      ],
      "metadata": {
        "id": "_OWz-jqS40Th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwHI6aDY_aNX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!git clone https://github.com/rignitc/hAIck.py_2025.git\n",
        "os.chdir('hAIck.py_2025')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Installing Python dependencies"
      ],
      "metadata": {
        "id": "B7oX8vTY4-cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets faiss-gpu-cu12 langchain langchain_community langchain-openai scikit-learn langchain-ollama langchain faiss-cpu sentence-transformers pyngrok\n",
        "!pip install streamlit -q\n",
        "!apt install lshw"
      ],
      "metadata": {
        "id": "edbs4oIYVTS0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3**: Install ollama CLI app"
      ],
      "metadata": {
        "id": "qMNsgsX65GT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "Ie637XT2VUxP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Running ollama server and pulling ollama3.1 LLM model"
      ],
      "metadata": {
        "id": "nU7vQ6_W5ZbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"ollama serve &\")"
      ],
      "metadata": {
        "id": "HJnJqfDSjNbI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.1"
      ],
      "metadata": {
        "id": "23pH5yTVTmug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5**: Start ngrok server and expose the app"
      ],
      "metadata": {
        "id": "xyBeZRWj5inS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!pkill ngrok\n",
        "!pkill streamlit\n",
        "\n",
        "# Set authentication token\n",
        "ngrok.set_auth_token(\"2r8P6Ni1zQrVsBIBWXcxYgM86Vp_3v6MrwKNT2J52Y2m8cKmr\")\n",
        "\n",
        "# Start Streamlit server on a specific port\n",
        "!nohup streamlit run rag-main.py --server.port 5011 &\n",
        "\n",
        "# Start ngrok tunnel to expose the Streamlit server\n",
        "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
        "\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "DA5mcjD88v0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill ngrok\n",
        "# !pkill streamlit"
      ],
      "metadata": {
        "id": "Xh-GrpcxNK3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Export current working files as zip file, uncomment it and run it if a local copy of the files are required"
      ],
      "metadata": {
        "id": "Tjmlt3FA6FqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('..')\n",
        "# !ls"
      ],
      "metadata": {
        "id": "p7FnBCIV8P0U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# !rm -rf hAIck.py_2025/nohup.out hAIck.py_2025/.git/*\n",
        "# !zip -r hAIck.py_2025.zip hAIck.py_2025/\n",
        "# files.download('hAIck.py_2025.zip')"
      ],
      "metadata": {
        "id": "6aRk0ce17h43",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
